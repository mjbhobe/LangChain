{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Large Language Models, the Chat Format and Tokens\n",
    "##### Setup\n",
    "Load the API key and relevant Python libaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install openai\n",
    "#!pip install tiktoken\n",
    "#!pip install dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "import tiktoken\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())  # read local .env file\n",
    "\n",
    "openai.api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0,\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Prompt the model and get completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of France is Paris.\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"What is the capital of France?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reversed letters of \"lollipop\" are \"pillipol\".\n"
     ]
    }
   ],
   "source": [
    "response = get_completion(\"Take the letters in lollipop and reverse them\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p-o-p-i-l-l-o-l\n"
     ]
    }
   ],
   "source": [
    "# that was incorrect. What about this?\n",
    "response = get_completion(\n",
    "    \"\"\"Take the letters in \\\n",
    "l-o-l-l-i-p-o-p and reverse them\"\"\"\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Helper function (chat format)Â¶\n",
    "Here's the helper function we'll use in the following cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_from_messages(\n",
    "    messages,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    max_tokens=500,\n",
    "):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,  # this is the degree of randomness of the model's output\n",
    "        max_tokens=max_tokens,  # the maximum number of tokens the model can ouptut\n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In a garden so cheery, a carrot did grow,\n",
      "With a smile on its face, it wanted to show,\n",
      "It stretched its orange self, up high in the air,\n",
      "So proud to be tasty, and oh-so rare.\n",
      "\n",
      "With friends all around, it danced and did sing,\n",
      "A happy little carrot, a joy it would bring,\n",
      "It giggled with glee, as it wiggled its root,\n",
      "Bringing laughter and smiles, from harvest to boot.\n",
      "\n",
      "With sunshine above and dirt at its feet,\n",
      "This carrot was happy, so sweet and so neat,\n",
      "It brightened the garden, it brightened the day,\n",
      "A happy little carrot, forever at play.\n",
      "\n",
      "So remember this tale, whenever you see,\n",
      "A carrot so happy, just like you and me,\n",
      "With joy in our hearts, and a smile so bright,\n",
      "We'll make the world happier, with all of our might!\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are an assistant who responds in the style of Dr Seuss.\"\"\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"\"\"write me a very short poem about a happy carrot\"\"\"},\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a cheerful carrot named Carl who lived in a sunny vegetable garden.\n"
     ]
    }
   ],
   "source": [
    "# length\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"All your responses must be one sentence long.\"},\n",
    "    {\"role\": \"user\", \"content\": \"write me a story about a happy carrot\"},\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time in a garden so bright, there was a happy carrot, oh what a delight!\n"
     ]
    }
   ],
   "source": [
    "# combined\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are an assistant who responds in the style of Dr Seuss. \\\n",
    "All your responses must be one sentence long.\"\"\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"\"\"write me a story about a happy carrot\"\"\"},\n",
    "]\n",
    "response = get_completion_from_messages(messages, temperature=1)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion_and_token_count(\n",
    "    messages,\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0,\n",
    "    max_tokens=500,\n",
    "):\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "\n",
    "    content = response.choices[0].message[\"content\"]\n",
    "\n",
    "    token_dict = {\n",
    "        \"prompt_tokens\": response[\"usage\"][\"prompt_tokens\"],\n",
    "        \"completion_tokens\": response[\"usage\"][\"completion_tokens\"],\n",
    "        \"total_tokens\": response[\"usage\"][\"total_tokens\"],\n",
    "    }\n",
    "\n",
    "    return content, token_dict, response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"You are an assistant who responds in the style of Dr Seuss.\"\"\",\n",
    "    },\n",
    "    {\"role\": \"user\", \"content\": \"\"\"write me a very short poem  about a happy carrot\"\"\"},\n",
    "]\n",
    "response, token_dict, content = get_completion_and_token_count(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh, the happy carrot, so bright and orange,\n",
      "With a smile so wide, it's hard to manage.\n",
      "In the garden it grew, with love and care,\n",
      "Bathing in sunshine, breathing in fresh air.\n",
      "\n",
      "Its roots dug deep, in the soil so fine,\n",
      "Growing tall and strong, like a vine.\n",
      "With every day that passed, it grew so sweet,\n",
      "A tasty treat, for all to eat.\n",
      "\n",
      "From the ground it was plucked, with a joyful cheer,\n",
      "For the happy carrot had nothing to fear.\n",
      "It brought smiles to faces, with its crunch and taste,\n",
      "A veggie delight, not a moment to waste.\n",
      "\n",
      "So let's celebrate the happy carrot, so grand,\n",
      "A vibrant veggie, grown by nature's hand.\n",
      "With every bite, a burst of joy and glee,\n",
      "Oh, happy carrot, you make us so happy!\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'prompt_tokens': 36, 'completion_tokens': 174, 'total_tokens': 210}\n"
     ]
    }
   ],
   "source": [
    "print(token_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"id\": \"chatcmpl-8EG071dV7auLbriG6e4X9HLbomxpP\",\n",
      "  \"object\": \"chat.completion\",\n",
      "  \"created\": 1698408791,\n",
      "  \"model\": \"gpt-3.5-turbo-0613\",\n",
      "  \"choices\": [\n",
      "    {\n",
      "      \"index\": 0,\n",
      "      \"message\": {\n",
      "        \"role\": \"assistant\",\n",
      "        \"content\": \"Oh, the happy carrot, so bright and orange,\\nWith a smile so wide, it's hard to manage.\\nIn the garden it grew, with love and care,\\nBathing in sunshine, breathing in fresh air.\\n\\nIts roots dug deep, in the soil so fine,\\nGrowing tall and strong, like a vine.\\nWith every day that passed, it grew so sweet,\\nA tasty treat, for all to eat.\\n\\nFrom the ground it was plucked, with a joyful cheer,\\nFor the happy carrot had nothing to fear.\\nIt brought smiles to faces, with its crunch and taste,\\nA veggie delight, not a moment to waste.\\n\\nSo let's celebrate the happy carrot, so grand,\\nA vibrant veggie, grown by nature's hand.\\nWith every bite, a burst of joy and glee,\\nOh, happy carrot, you make us so happy!\"\n",
      "      },\n",
      "      \"finish_reason\": \"stop\"\n",
      "    }\n",
      "  ],\n",
      "  \"usage\": {\n",
      "    \"prompt_tokens\": 36,\n",
      "    \"completion_tokens\": 174,\n",
      "    \"total_tokens\": 210\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print(content)  # the entire original response from LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
