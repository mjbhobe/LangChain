{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Langchain - Memory\n",
    "\n",
    "Large Language Models (LLMs) do not \"remember\" any of your \"previous\" conversations - each interaction is distinct from the other. This is an issue, especially when you are building chatbots, where you want to have a conversation where LLM must \"know\" previous conversations in the thread.\n",
    "\n",
    "Langchain provides \"Memory\" which helps LLM \"remember\" previous interactions and feed that into the model, so you can have the conversational flow as you chat with them.\n",
    "\n",
    "In this workbook we'll cover\n",
    "* ConversationBufferMemory\n",
    "* ConversationBufferWindowMemory\n",
    "* ConversationTokenBufferMemory\n",
    "* ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load my LLM keys from .env files\n",
    "import os\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "\n",
    "_ = load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client=<openai.resources.chat.completions.Completions object at 0x0000022A82EBEEA0> async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x0000022A82EC1B20> root_client=<openai.OpenAI object at 0x0000022A81B94770> root_async_client=<openai.AsyncOpenAI object at 0x0000022A82EBE480> temperature=0.0 model_kwargs={} openai_api_key=SecretStr('**********') max_retries=2 max_tokens=2048\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    temperature=0.0,\n",
    "    model=\"gpt-3.5-turbo\",  # enough for this tutorial\n",
    "    max_tokens=2048,\n",
    "    max_retries=2,\n",
    "    verbose=False,\n",
    ")\n",
    "print(chat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(chat_model, message, config=None):\n",
    "    messages = [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant that responds to the user in a calm and respectful tone\",\n",
    "        ),\n",
    "        (\"human\", message),\n",
    "    ]\n",
    "    if config is not None:\n",
    "        response = chat_model.invoke(messages, config=config)\n",
    "    else:\n",
    "        response = chat_model.invoke(messages)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Manish! Welcome to the world of Generative AI. I'm here to help you with any questions you may have. What would you like to know or learn about Generative AI?\n"
     ]
    }
   ],
   "source": [
    "# now let's start chatting\n",
    "response = get_response(\n",
    "    chat_model, \"Hi! My name is Manish and I am new to Generative AI\"\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but I don't have access to personal information like your name. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "response = get_response(chat_model, \"What was my name?\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to memory enable the LLM\n",
    "from langchain_core.chat_history import (\n",
    "    BaseChatMessageHistory,\n",
    "    InMemoryChatMessageHistory,\n",
    ")\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "# this is my message & response store\n",
    "store = {}\n",
    "\n",
    "\n",
    "def get_session_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id] = InMemoryChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n",
    "\n",
    "chat_model_with_memory = RunnableWithMessageHistory(chat_model, get_session_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "now_str = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "session_id = f\"mjb4genai{now_str}\"\n",
    "\n",
    "config = {\"configurable\": {\"session_id\": session_id}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Manish! Welcome to the world of Generative AI. I'm here to help you with any questions you may have. What would you like to know or learn about Generative AI?\n"
     ]
    }
   ],
   "source": [
    "response = get_response(\n",
    "    chat_model_with_memory,\n",
    "    \"Hi! My name is Manish and I am new to Generative AI\",\n",
    "    config=config,\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mjb4genai20250113_115748': InMemoryChatMessageHistory(messages=[SystemMessage(content='You are a helpful assistant that responds to the user in a calm and respectful tone', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hi! My name is Manish and I am new to Generative AI', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Manish! Welcome to the world of Generative AI. I'm here to help you with any questions you may have. What would you like to know or learn about Generative AI?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 42, 'total_tokens': 82, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-77a73ef4-e0f6-46a5-8cb6-419926772352-0', usage_metadata={'input_tokens': 42, 'output_tokens': 40, 'total_tokens': 82, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])}\n"
     ]
    }
   ],
   "source": [
    "print(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An AI agent is a software program that acts on behalf of a user or another program to perform specific tasks or make decisions. AI agents can be designed to operate autonomously or with human guidance, depending on the application. They are commonly used in various fields such as robotics, virtual assistants, and autonomous vehicles to assist users in completing tasks efficiently. If you have any more questions or need further clarification, feel free to ask!\n"
     ]
    }
   ],
   "source": [
    "response = get_response(\n",
    "    chat_model_with_memory,\n",
    "    \"What is an AI Agent?\",\n",
    "    config=config,\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mjb4genai20250113_115748': InMemoryChatMessageHistory(messages=[SystemMessage(content='You are a helpful assistant that responds to the user in a calm and respectful tone', additional_kwargs={}, response_metadata={}), HumanMessage(content='Hi! My name is Manish and I am new to Generative AI', additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hello Manish! Welcome to the world of Generative AI. I'm here to help you with any questions you may have. What would you like to know or learn about Generative AI?\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 40, 'prompt_tokens': 42, 'total_tokens': 82, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-77a73ef4-e0f6-46a5-8cb6-419926772352-0', usage_metadata={'input_tokens': 42, 'output_tokens': 40, 'total_tokens': 82, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}}), SystemMessage(content='You are a helpful assistant that responds to the user in a calm and respectful tone', additional_kwargs={}, response_metadata={}), HumanMessage(content='What is an AI Agent?', additional_kwargs={}, response_metadata={}), AIMessage(content='An AI agent is a software program that acts on behalf of a user or another program to perform specific tasks or make decisions. AI agents can be designed to operate autonomously or with human guidance, depending on the application. They are commonly used in various fields such as robotics, virtual assistants, and autonomous vehicles to assist users in completing tasks efficiently. If you have any more questions or need further clarification, feel free to ask!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 86, 'prompt_tokens': 115, 'total_tokens': 201, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-4491a567-28ca-4d57-b686-3d7b1ad308de-0', usage_metadata={'input_tokens': 115, 'output_tokens': 86, 'total_tokens': 201, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})])}\n"
     ]
    }
   ],
   "source": [
    "print(store)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your name is Manish. How can I assist you further, Manish?\n"
     ]
    }
   ],
   "source": [
    "response = get_response(\n",
    "    chat_model_with_memory,\n",
    "    \"What was my name?\",\n",
    "    config=config,\n",
    ")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
